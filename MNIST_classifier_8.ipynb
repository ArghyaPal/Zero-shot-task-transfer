{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_classifier_8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Fv0SIFA1ncXcCn8jXlAYX8GHbFVjz1aE",
      "authorship_tag": "ABX9TyN99QcUZR1ZOllaPsz5gLLz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArghyaPal/Zero-shot-task-transfer/blob/master/MNIST_classifier_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydiRi9pzJ193",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "jj=0\n",
        "for jj in range(20):  # loop over the dataset multiple times\n",
        "\n",
        "    import os\n",
        "    import torch\n",
        "    import torchvision\n",
        "    import torch.nn as nn\n",
        "    from torchvision import transforms\n",
        "    from torchvision.utils import save_image\n",
        "    from torch.autograd import Variable\n",
        "\n",
        "    from torch.utils.data import DataLoader\n",
        "    from torch.utils.data import Dataset\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    seed = jj\n",
        "    print(\"Seed Number Starting:\")\n",
        "    print(seed)\n",
        "    print('\\n')\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # Decide which device we want to run on\n",
        "    ngpu = 4\n",
        "    device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "\n",
        "    ## Hyperparameteres for this work\n",
        "    # The noise dimension for the Generator, i.e. the z dimension, sampled from a Gaussian Distribution\n",
        "    latent_size = 64\n",
        "    # The network layer dimension of Generator and Discriminator\n",
        "    hidden_size = 256\n",
        "    # The generated image size/image size. MNIST size 28 X 28 = 784\n",
        "    image_size = 784\n",
        "    # The number of channels\n",
        "    nchannel = 1\n",
        "    # Number of epochs\n",
        "    num_epochs = 3\n",
        "    # A mini-batch size\n",
        "    batch_size = 20\n",
        "    # Adam learning rate\n",
        "    lr = 0.0001\n",
        "\n",
        "    # Number of classes\n",
        "    nclass = 10          # For MNIST dataset, please change it for other dataset\n",
        "\n",
        "    # Image processing\n",
        "    transform = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(mean=(0.5),   # 3 for RGB channels\n",
        "                                        std=(0.5))])\n",
        "\n",
        "\n",
        "    # MNIST dataset\n",
        "    mnist = torchvision.datasets.MNIST(root='./data/',\n",
        "                                      train=True,\n",
        "                                      transform=transform,\n",
        "                                      download=True)\n",
        "\n",
        "    # Class with label 0\n",
        "    idx_other = mnist.train_labels == 8  # <---- Class \n",
        "    mnist.train_labels[idx_other] = 1\n",
        "\n",
        "    # All other classses\n",
        "    idx_other = mnist.train_labels != 8   # <---- Class\n",
        "    mnist.train_data[idx_other]   = 0\n",
        "    mnist.train_labels[idx_other] = 0\n",
        "\n",
        "    # Data loader\n",
        "    trainloader = torch.utils.data.DataLoader(dataset=mnist,\n",
        "                                              batch_size=batch_size, \n",
        "                                              shuffle=True)\n",
        "\n",
        "    import torch.nn.functional as F\n",
        "\n",
        "    class Net(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(Net, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(nchannel, 3, 5)\n",
        "            self.pool1 = nn.MaxPool2d(2, 2)\n",
        "            self.conv2 = nn.Conv2d(3, 6, 5)\n",
        "            self.pool2 = nn.MaxPool2d(2, 2)\n",
        "            self.fc1 = nn.Linear(6 * 4 * 4, nclass)\n",
        "            #self.fc2 = nn.Linear(44, 10)\n",
        "            self.relu = nn.ReLU()\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.pool1(self.relu(self.conv1(x)))\n",
        "            x = self.pool2(self.relu(self.conv2(x)))\n",
        "            x = x.view(-1, 6 * 4 * 4)\n",
        "            x = self.fc1(x)\n",
        "            #x = self.relu(self.fc1(x))\n",
        "            #x = self.fc2(x)\n",
        "            return x\n",
        "\n",
        "    net = Net()\n",
        "\n",
        "    import torch.optim as optim\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    model_dir = './models'\n",
        "\n",
        "    # Create a directory if not exists\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "            running_loss = 0.0\n",
        "            for i, data in enumerate(trainloader):\n",
        "                #### get the inputs\n",
        "                inputs, labels = data\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward + backward + optimize\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # print statistics\n",
        "                running_loss += loss.item()\n",
        "                if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                    print('[%d, %5d] loss: %.3f' %\n",
        "                          (epoch + 1, i + 1, running_loss / 2000))\n",
        "                    running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "    from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
        "\n",
        "    one_parameter =  '/content/drive/My Drive/Keyword/8_real_'+str(seed)+'.pt'\n",
        "    vec1 = parameters_to_vector(net.parameters())\n",
        "    torch.save(vec1, one_parameter)\n",
        "    print(\"Finished seed\")\n",
        "    print(jj)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}